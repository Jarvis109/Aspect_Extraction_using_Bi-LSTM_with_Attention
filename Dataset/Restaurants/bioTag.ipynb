{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1DQELmdw-SxIAQLdBVZ_HJ0M8LawI_zqy","authorship_tag":"ABX9TyP0V5up3QoeaR2kng25W0KU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YI-8bi5YQPZ","executionInfo":{"status":"ok","timestamp":1709454105918,"user_tz":-330,"elapsed":711,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"57478c88-ec96-4946-899a-5280191061b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                               token  \\\n","0  [The, food, is, uniformly, exceptional, ,, wit...   \n","1  [The, food, is, uniformly, exceptional, ,, wit...   \n","\n","                                              aspect  \\\n","0  [{'term': ['food']}, {'term': ['kitchen']}, {'...   \n","1                               [{'term': ['food']}]   \n","\n","                                              bioTag  \\\n","0  [O, B, O, O, O, O, O, O, O, O, B, O, O, O, O, ...   \n","1  [O, B, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n","\n","                                        token_length  \n","0  [3, 4, 2, 9, 11, 1, 4, 1, 4, 7, 7, 5, 4, 7, 4,...  \n","1  [3, 4, 2, 9, 11, 1, 4, 1, 4, 7, 7, 5, 4, 7, 4,...  \n"]}],"source":["import pandas as pd\n","\n","data = [\n","    {\n","        \"token\": [\n","            \"The\", \"food\", \"is\", \"uniformly\", \"exceptional\", \",\", \"with\", \"a\", \"very\", \"capable\", \"kitchen\", \"which\",\n","            \"will\", \"proudly\", \"whip\", \"up\", \"whatever\", \"you\", \"feel\", \"like\", \"eating\", \",\", \"whether\", \"it\", \"'s\",\n","            \"on\", \"the\", \"menu\", \"or\", \"not\", \".\"\n","        ],\n","        \"aspects\": [\n","            {\"term\": [\"food\"]},\n","            {\"term\": [\"kitchen\"]},\n","            {\"term\": [\"menu\"]}\n","        ]\n","    },\n","    {\n","        \"token\": [\n","            \"The\", \"food\", \"is\", \"uniformly\", \"exceptional\", \",\", \"with\", \"a\", \"very\", \"capable\", \"kitchen\", \"which\",\n","            \"will\", \"proudly\", \"whip\", \"up\", \"whatever\", \"you\", \"feel\", \"like\", \"eating\", \",\", \"whether\", \"it\", \"'s\",\n","            \"on\", \"the\", \"menu\", \"or\", \"not\", \".\"\n","        ],\n","        \"aspects\": [\n","            {\"term\": [\"food\"]}\n","        ]\n","    }\n","]\n","\n","# Initialize empty lists for each column\n","tokens_list = []\n","aspects_list = []\n","bio_tags_list = []\n","token_length_list = []\n","\n","# Process each entry in the data\n","for entry in data:\n","    tokens = entry[\"token\"]\n","    aspects = entry.get(\"aspects\", [])\n","\n","    # Initialize BIO tags list with 'O' (outside) for each token\n","    bio_tags = ['O'] * len(tokens)\n","\n","    # Process aspects and update BIO tags accordingly\n","    for aspect in aspects:\n","        term = aspect.get(\"term\", [])\n","        for i in range(len(tokens)):\n","            if tokens[i] in term:\n","                if len(term) == 1:\n","                    bio_tags[i] = 'B'\n","                else:\n","                    bio_tags[i] = 'B'\n","                    bio_tags[i + 1:i + len(term)] = ['I'] * (len(term) - 1)\n","\n","    # Append data to lists\n","    tokens_list.append(tokens)\n","    aspects_list.append(aspects)\n","    bio_tags_list.append(bio_tags)\n","    token_length_list.append([len(token) for token in tokens])\n","\n","# Create DataFrame\n","df = pd.DataFrame({\n","    'token': tokens_list,\n","    'aspect': aspects_list,\n","    'bioTag': bio_tags_list,\n","    'token_length': token_length_list\n","})\n","\n","# Display the DataFrame\n","print(df)\n"]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","\n","# Assuming your JSON file is named 'your_file.json'\n","json_file_path = '/content/drive/MyDrive/Common files/Common files/Dataset/Restaurants/train.json'\n","\n","# Read data from JSON file\n","with open(json_file_path, 'r') as file:\n","    data = json.load(file)\n","\n","# Initialize empty lists for each column\n","tokens_list = []\n","aspects_list = []\n","bio_tags_list = []\n","token_length_list = []\n","\n","# Process each entry in the data\n","for entry in data:\n","    tokens = entry[\"token\"]\n","    aspects = entry.get(\"aspects\", [])\n","\n","    # Initialize BIO tags list with 'O' (outside) for each token\n","    bio_tags = ['O'] * len(tokens)\n","\n","    # Process aspects and update BIO tags accordingly\n","    for aspect in aspects:\n","        term = aspect.get(\"term\", [])\n","        for i in range(len(tokens)):\n","            if tokens[i] in term:\n","                if len(term) == 1:\n","                    bio_tags[i] = 'B'\n","                else:\n","                    bio_tags[i] = 'B'\n","                    bio_tags[i + 1:i + len(term)] = ['I'] * (len(term) - 1)\n","\n","    # Append data to lists\n","    tokens_list.append(tokens)\n","    aspects_list.append(aspects)\n","    bio_tags_list.append(bio_tags)\n","    token_length_list.append([len(token) for token in tokens])\n","\n","# Create DataFrame\n","df_result = pd.DataFrame({\n","    'token': tokens_list,\n","    'aspect': aspects_list,\n","    'bioTag': bio_tags_list,\n","    'token_length': token_length_list\n","})\n","\n","# Display the DataFrame\n","print(df_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrHZl4WjaR9J","executionInfo":{"status":"ok","timestamp":1709454313519,"user_tz":-330,"elapsed":719,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"5243641a-e51b-44a4-cab2-c3023f493f13"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  token  \\\n","0       [But, the, staff, was, so, horrible, to, us, .]   \n","1     [To, be, completely, fair, ,, the, only, redee...   \n","2     [The, food, is, uniformly, exceptional, ,, wit...   \n","3     [Not, only, was, the, food, outstanding, ,, bu...   \n","4     [Our, agreed, favorite, is, the, orrechiete, w...   \n","...                                                 ...   \n","1975  [The, service, was, typical, short-order, ,, d...   \n","1976  [We, shared, a, bottle, of, sake, ,, an, order...   \n","1977  [I, ca, n't, believe, people, complain, about,...   \n","1978  [From, the, appetizers, we, ate, ,, the, dim, ...   \n","1979  [Each, table, has, a, pot, of, boiling, water,...   \n","\n","                                                 aspect  \\\n","0     [{'term': ['staff'], 'from': 2, 'to': 3, 'pola...   \n","1     [{'term': ['food'], 'from': 11, 'to': 12, 'pol...   \n","2     [{'term': ['food'], 'from': 1, 'to': 2, 'polar...   \n","3     [{'term': ['food'], 'from': 4, 'to': 5, 'polar...   \n","4     [{'term': ['orrechiete', 'with', 'sausage', 'a...   \n","...                                                 ...   \n","1975  [{'term': ['service'], 'from': 1, 'to': 2, 'po...   \n","1976  [{'term': ['bottle', 'of', 'sake'], 'from': 3,...   \n","1977  [{'term': ['cheese', 'sticks'], 'from': 8, 'to...   \n","1978  [{'term': ['appetizers'], 'from': 2, 'to': 3, ...   \n","1979  [{'term': ['table'], 'from': 1, 'to': 2, 'pola...   \n","\n","                                                 bioTag  \\\n","0                           [O, O, B, O, O, O, O, O, O]   \n","1     [O, O, O, O, O, O, O, O, O, O, O, B, O, O, O, ...   \n","2     [O, B, O, O, O, O, O, O, O, O, B, O, O, O, O, ...   \n","3      [O, O, O, O, B, O, O, O, O, O, B, B, B, I, O, O]   \n","4     [O, O, O, O, O, B, B, B, B, B, I, I, I, B, O, ...   \n","...                                                 ...   \n","1975                        [O, B, O, O, O, O, O, O, O]   \n","1976  [O, O, O, B, B, B, I, I, O, B, B, I, O, O, O, ...   \n","1977                  [O, O, O, O, O, O, O, O, B, B, I]   \n","1978  [O, O, B, O, O, O, O, B, B, I, O, O, O, B, O, ...   \n","1979  [O, B, O, O, B, B, B, B, I, I, I, O, O, O, O, ...   \n","\n","                                           token_length  \n","0                           [3, 3, 5, 3, 2, 8, 2, 2, 1]  \n","1     [2, 2, 10, 4, 1, 3, 4, 9, 6, 3, 3, 4, 1, 5, 3,...  \n","2     [3, 4, 2, 9, 11, 1, 4, 1, 4, 7, 7, 5, 4, 7, 4,...  \n","3     [3, 4, 3, 3, 4, 11, 1, 3, 3, 6, 1, 5, 1, 4, 5, 1]  \n","4     [3, 6, 8, 2, 3, 10, 4, 7, 3, 7, 1, 7, 3, 7, 3,...  \n","...                                                 ...  \n","1975                       [3, 7, 3, 7, 11, 1, 6, 4, 1]  \n","1976  [2, 6, 1, 6, 2, 4, 1, 2, 5, 2, 8, 1, 3, 3, 3, ...  \n","1977                  [1, 2, 3, 7, 6, 8, 5, 2, 6, 6, 1]  \n","1978  [4, 3, 10, 2, 3, 1, 3, 3, 3, 3, 5, 7, 2, 5, 1,...  \n","1979  [4, 5, 3, 1, 3, 2, 7, 5, 6, 4, 3, 7, 1, 3, 3, ...  \n","\n","[1980 rows x 4 columns]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","\n","# Assuming your JSON file is named 'your_file.json'\n","json_file_path = '/content/drive/MyDrive/Common files/Common files/Dataset/Restaurants/train.json'\n","\n","# Read data from JSON file\n","with open(json_file_path, 'r') as file:\n","    data = json.load(file)\n","\n","# Initialize empty lists for each column\n","tokens_list = []\n","aspects_list = []\n","bio_tags_list = []\n","token_length_list = []\n","\n","# Process each entry in the data\n","for entry in data:\n","    tokens = entry[\"token\"]\n","    aspects = entry.get(\"aspects\", [])\n","\n","    # Extract unique aspects as a list of terms\n","    unique_aspects = list(set(term for aspect in aspects for term in aspect.get(\"term\", [])))\n","\n","    # Initialize BIO tags list with 'O' (outside) for each token\n","    bio_tags = ['O'] * len(tokens)\n","\n","    # Process aspects and update BIO tags accordingly\n","    for aspect in aspects:\n","        term = aspect.get(\"term\", [])\n","        for i in range(len(tokens)):\n","            if tokens[i] in term:\n","                if len(term) == 1:\n","                    bio_tags[i] = 'B'\n","                else:\n","                    bio_tags[i] = 'B'\n","                    bio_tags[i + 1:i + len(term)] = ['I'] * (len(term) - 1)\n","\n","    # Append data to lists\n","    tokens_list.append(tokens)\n","    aspects_list.append(unique_aspects)  # Append unique aspects\n","    bio_tags_list.append(bio_tags)\n","    token_length_list.append([len(token) for token in tokens])\n","\n","# Create DataFrame\n","df_result = pd.DataFrame({\n","    'token': tokens_list,\n","    'aspect': aspects_list,\n","    'bioTag': bio_tags_list,\n","    'token_length': token_length_list\n","})\n","\n","# Display the DataFrame\n","print(df_result)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQcku1Sgbych","executionInfo":{"status":"ok","timestamp":1709454634216,"user_tz":-330,"elapsed":1026,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"18536222-7045-423c-f615-09a4772d8b1d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  token  \\\n","0       [But, the, staff, was, so, horrible, to, us, .]   \n","1     [To, be, completely, fair, ,, the, only, redee...   \n","2     [The, food, is, uniformly, exceptional, ,, wit...   \n","3     [Not, only, was, the, food, outstanding, ,, bu...   \n","4     [Our, agreed, favorite, is, the, orrechiete, w...   \n","...                                                 ...   \n","1975  [The, service, was, typical, short-order, ,, d...   \n","1976  [We, shared, a, bottle, of, sake, ,, an, order...   \n","1977  [I, ca, n't, believe, people, complain, about,...   \n","1978  [From, the, appetizers, we, ate, ,, the, dim, ...   \n","1979  [Each, table, has, a, pot, of, boiling, water,...   \n","\n","                                                 aspect  \\\n","0                                               [staff]   \n","1                                                [food]   \n","2                                 [kitchen, food, menu]   \n","3                                      [food, perks, ']   \n","4     [sausage, chicken, and, dish, meats, with, orr...   \n","...                                                 ...   \n","1975                                          [service]   \n","1976  [sake, of, edamames, sushi, bottle, sashimi, p...   \n","1977                                   [sticks, cheese]   \n","1978                [food, dim, foods, sum, appetizers]   \n","1979  [of, pot, glass, noodles, meats, vegetables, r...   \n","\n","                                                 bioTag  \\\n","0                           [O, O, B, O, O, O, O, O, O]   \n","1     [O, O, O, O, O, O, O, O, O, O, O, B, O, O, O, ...   \n","2     [O, B, O, O, O, O, O, O, O, O, B, O, O, O, O, ...   \n","3      [O, O, O, O, B, O, O, O, O, O, B, B, B, I, O, O]   \n","4     [O, O, O, O, O, B, B, B, B, B, I, I, I, B, O, ...   \n","...                                                 ...   \n","1975                        [O, B, O, O, O, O, O, O, O]   \n","1976  [O, O, O, B, B, B, I, I, O, B, B, I, O, O, O, ...   \n","1977                  [O, O, O, O, O, O, O, O, B, B, I]   \n","1978  [O, O, B, O, O, O, O, B, B, I, O, O, O, B, O, ...   \n","1979  [O, B, O, O, B, B, B, B, I, I, I, O, O, O, O, ...   \n","\n","                                           token_length  \n","0                           [3, 3, 5, 3, 2, 8, 2, 2, 1]  \n","1     [2, 2, 10, 4, 1, 3, 4, 9, 6, 3, 3, 4, 1, 5, 3,...  \n","2     [3, 4, 2, 9, 11, 1, 4, 1, 4, 7, 7, 5, 4, 7, 4,...  \n","3     [3, 4, 3, 3, 4, 11, 1, 3, 3, 6, 1, 5, 1, 4, 5, 1]  \n","4     [3, 6, 8, 2, 3, 10, 4, 7, 3, 7, 1, 7, 3, 7, 3,...  \n","...                                                 ...  \n","1975                       [3, 7, 3, 7, 11, 1, 6, 4, 1]  \n","1976  [2, 6, 1, 6, 2, 4, 1, 2, 5, 2, 8, 1, 3, 3, 3, ...  \n","1977                  [1, 2, 3, 7, 6, 8, 5, 2, 6, 6, 1]  \n","1978  [4, 3, 10, 2, 3, 1, 3, 3, 3, 3, 5, 7, 2, 5, 1,...  \n","1979  [4, 5, 3, 1, 3, 2, 7, 5, 6, 4, 3, 7, 1, 3, 3, ...  \n","\n","[1980 rows x 4 columns]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","\n","# Assuming your JSON file is named 'your_file.json'\n","json_file_path = '/content/drive/MyDrive/Common files/Common files/Dataset/Restaurants/train.json'\n","\n","# Read data from JSON file\n","with open(json_file_path, 'r') as file:\n","    data = json.load(file)\n","\n","# Initialize empty lists for each column\n","tokens_list = []\n","aspects_list = []\n","bio_tags_list = []\n","token_length_list = []\n","\n","# Process each entry in the data\n","for entry in data:\n","    tokens = entry[\"token\"]\n","    aspects = entry.get(\"aspects\", [])\n","\n","    # Extract unique aspects as a list of terms\n","    unique_aspects = list(set(term for aspect in aspects for term in aspect.get(\"term\", [])))\n","\n","    # Initialize BIO tags list with 'O' (outside) for each token\n","    bio_tags = ['O'] * len(tokens)\n","\n","    # Process aspects and update BIO tags accordingly\n","    for aspect in aspects:\n","        term = aspect.get(\"term\", [])\n","        for i in range(len(tokens)):\n","            if tokens[i] in term:\n","                if len(term) == 1:\n","                    bio_tags[i] = 'B'\n","                else:\n","                    bio_tags[i] = 'B'\n","                    bio_tags[i + 1:i + len(term)] = ['I'] * (len(term) - 1)\n","\n","    # Append data to lists\n","    tokens_list.append(tokens)\n","    aspects_list.append(unique_aspects)  # Append unique aspects\n","    bio_tags_list.append(bio_tags)\n","    token_length_list.append([len(token) for token in tokens])\n","\n","# Create DataFrame\n","df_result = pd.DataFrame({\n","    'token': tokens_list,\n","    'aspect': aspects_list,\n","    'bioTag': bio_tags_list,\n","    'token_length': token_length_list\n","})\n","\n","# Save DataFrame to CSV file\n","csv_output_path = 'output_file.csv'\n","df_result.to_csv(csv_output_path, index=False)\n","\n","# Display the DataFrame\n","print(df_result)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFDxUeUzckee","executionInfo":{"status":"ok","timestamp":1709454828028,"user_tz":-330,"elapsed":463,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"850ebe00-583a-48d1-c778-3ff2d567a9e2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  token  \\\n","0       [But, the, staff, was, so, horrible, to, us, .]   \n","1     [To, be, completely, fair, ,, the, only, redee...   \n","2     [The, food, is, uniformly, exceptional, ,, wit...   \n","3     [Not, only, was, the, food, outstanding, ,, bu...   \n","4     [Our, agreed, favorite, is, the, orrechiete, w...   \n","...                                                 ...   \n","1975  [The, service, was, typical, short-order, ,, d...   \n","1976  [We, shared, a, bottle, of, sake, ,, an, order...   \n","1977  [I, ca, n't, believe, people, complain, about,...   \n","1978  [From, the, appetizers, we, ate, ,, the, dim, ...   \n","1979  [Each, table, has, a, pot, of, boiling, water,...   \n","\n","                                                 aspect  \\\n","0                                               [staff]   \n","1                                                [food]   \n","2                                 [kitchen, food, menu]   \n","3                                      [food, perks, ']   \n","4     [sausage, chicken, and, dish, meats, with, orr...   \n","...                                                 ...   \n","1975                                          [service]   \n","1976  [sake, of, edamames, sushi, bottle, sashimi, p...   \n","1977                                   [sticks, cheese]   \n","1978                [food, dim, foods, sum, appetizers]   \n","1979  [of, pot, glass, noodles, meats, vegetables, r...   \n","\n","                                                 bioTag  \\\n","0                           [O, O, B, O, O, O, O, O, O]   \n","1     [O, O, O, O, O, O, O, O, O, O, O, B, O, O, O, ...   \n","2     [O, B, O, O, O, O, O, O, O, O, B, O, O, O, O, ...   \n","3      [O, O, O, O, B, O, O, O, O, O, B, B, B, I, O, O]   \n","4     [O, O, O, O, O, B, B, B, B, B, I, I, I, B, O, ...   \n","...                                                 ...   \n","1975                        [O, B, O, O, O, O, O, O, O]   \n","1976  [O, O, O, B, B, B, I, I, O, B, B, I, O, O, O, ...   \n","1977                  [O, O, O, O, O, O, O, O, B, B, I]   \n","1978  [O, O, B, O, O, O, O, B, B, I, O, O, O, B, O, ...   \n","1979  [O, B, O, O, B, B, B, B, I, I, I, O, O, O, O, ...   \n","\n","                                           token_length  \n","0                           [3, 3, 5, 3, 2, 8, 2, 2, 1]  \n","1     [2, 2, 10, 4, 1, 3, 4, 9, 6, 3, 3, 4, 1, 5, 3,...  \n","2     [3, 4, 2, 9, 11, 1, 4, 1, 4, 7, 7, 5, 4, 7, 4,...  \n","3     [3, 4, 3, 3, 4, 11, 1, 3, 3, 6, 1, 5, 1, 4, 5, 1]  \n","4     [3, 6, 8, 2, 3, 10, 4, 7, 3, 7, 1, 7, 3, 7, 3,...  \n","...                                                 ...  \n","1975                       [3, 7, 3, 7, 11, 1, 6, 4, 1]  \n","1976  [2, 6, 1, 6, 2, 4, 1, 2, 5, 2, 8, 1, 3, 3, 3, ...  \n","1977                  [1, 2, 3, 7, 6, 8, 5, 2, 6, 6, 1]  \n","1978  [4, 3, 10, 2, 3, 1, 3, 3, 3, 3, 5, 7, 2, 5, 1,...  \n","1979  [4, 5, 3, 1, 3, 2, 7, 5, 6, 4, 3, 7, 1, 3, 3, ...  \n","\n","[1980 rows x 4 columns]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","\n","# Assuming your JSON file is named 'your_file.json'\n","json_file_path = '/content/drive/MyDrive/Common files/Common files/Dataset/Restaurants/train.json'\n","\n","# Read data from JSON file\n","with open(json_file_path, 'r') as file:\n","    data = json.load(file)\n","\n","# Initialize empty lists for each column\n","tokens_list = []\n","aspects_list = []\n","bio_tags_list = []\n","token_length_list = []\n","\n","# Process each entry in the data\n","for entry in data:\n","    tokens = entry[\"token\"]\n","    aspects = entry.get(\"aspects\", [])\n","\n","    # Extract unique aspects as a list of terms\n","    unique_aspects = list(set(term for aspect in aspects for term in aspect.get(\"term\", [])))\n","\n","    # Initialize BIO tags list with 'O' (outside) for each token\n","    bio_tags = ['O'] * len(tokens)\n","\n","    # Process aspects and update BIO tags accordingly\n","    for aspect in aspects:\n","        term = aspect.get(\"term\", [])\n","        for i in range(len(tokens)):\n","            if tokens[i:i + len(term)] == term:\n","                bio_tags[i] = 'B'\n","                if len(term) > 1:\n","                    bio_tags[i + 1:i + len(term)] = ['I'] * (len(term) - 1)\n","\n","    # Append data to lists\n","    tokens_list.append(tokens)\n","    aspects_list.append(unique_aspects)  # Append unique aspects\n","    bio_tags_list.append(bio_tags)\n","    token_length_list.append([len(token) for token in tokens])\n","\n","# Create DataFrame\n","df_result = pd.DataFrame({\n","    'token': tokens_list,\n","    'aspect': aspects_list,\n","    'bioTag': bio_tags_list,\n","    'token_length': token_length_list\n","})\n","\n","# Display the DataFrame\n","print(df_result)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywIfw7cLensD","executionInfo":{"status":"ok","timestamp":1709455376666,"user_tz":-330,"elapsed":467,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"48268b31-b895-46f0-faf6-bf7bbc95d276"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  token  \\\n","0       [But, the, staff, was, so, horrible, to, us, .]   \n","1     [To, be, completely, fair, ,, the, only, redee...   \n","2     [The, food, is, uniformly, exceptional, ,, wit...   \n","3     [Not, only, was, the, food, outstanding, ,, bu...   \n","4     [Our, agreed, favorite, is, the, orrechiete, w...   \n","...                                                 ...   \n","1975  [The, service, was, typical, short-order, ,, d...   \n","1976  [We, shared, a, bottle, of, sake, ,, an, order...   \n","1977  [I, ca, n't, believe, people, complain, about,...   \n","1978  [From, the, appetizers, we, ate, ,, the, dim, ...   \n","1979  [Each, table, has, a, pot, of, boiling, water,...   \n","\n","                                                 aspect  \\\n","0                                               [staff]   \n","1                                                [food]   \n","2                                 [kitchen, food, menu]   \n","3                                      [food, perks, ']   \n","4     [sausage, chicken, and, dish, meats, with, orr...   \n","...                                                 ...   \n","1975                                          [service]   \n","1976  [sake, of, edamames, sushi, bottle, sashimi, p...   \n","1977                                   [sticks, cheese]   \n","1978                [food, dim, foods, sum, appetizers]   \n","1979  [of, pot, glass, noodles, meats, vegetables, r...   \n","\n","                                                 bioTag  \\\n","0                           [O, O, B, O, O, O, O, O, O]   \n","1     [O, O, O, O, O, O, O, O, O, O, O, B, O, O, O, ...   \n","2     [O, B, O, O, O, O, O, O, O, O, B, O, O, O, O, ...   \n","3      [O, O, O, O, B, O, O, O, O, O, B, I, O, O, O, O]   \n","4     [O, O, O, O, O, B, I, I, I, I, O, O, O, B, O, ...   \n","...                                                 ...   \n","1975                        [O, B, O, O, O, O, O, O, O]   \n","1976  [O, O, O, B, I, I, O, O, O, O, B, O, O, O, O, ...   \n","1977                  [O, O, O, O, O, O, O, O, B, I, O]   \n","1978  [O, O, B, O, O, O, O, B, I, O, O, O, O, B, O, ...   \n","1979  [O, B, O, O, B, I, I, I, O, O, O, O, O, O, O, ...   \n","\n","                                           token_length  \n","0                           [3, 3, 5, 3, 2, 8, 2, 2, 1]  \n","1     [2, 2, 10, 4, 1, 3, 4, 9, 6, 3, 3, 4, 1, 5, 3,...  \n","2     [3, 4, 2, 9, 11, 1, 4, 1, 4, 7, 7, 5, 4, 7, 4,...  \n","3     [3, 4, 3, 3, 4, 11, 1, 3, 3, 6, 1, 5, 1, 4, 5, 1]  \n","4     [3, 6, 8, 2, 3, 10, 4, 7, 3, 7, 1, 7, 3, 7, 3,...  \n","...                                                 ...  \n","1975                       [3, 7, 3, 7, 11, 1, 6, 4, 1]  \n","1976  [2, 6, 1, 6, 2, 4, 1, 2, 5, 2, 8, 1, 3, 3, 3, ...  \n","1977                  [1, 2, 3, 7, 6, 8, 5, 2, 6, 6, 1]  \n","1978  [4, 3, 10, 2, 3, 1, 3, 3, 3, 3, 5, 7, 2, 5, 1,...  \n","1979  [4, 5, 3, 1, 3, 2, 7, 5, 6, 4, 3, 7, 1, 3, 3, ...  \n","\n","[1980 rows x 4 columns]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","\n","# Assuming your JSON file is named 'your_file.json'\n","json_file_path = '/content/drive/MyDrive/Common files/Common files/Dataset/Restaurants/train.json'\n","\n","# Read data from JSON file\n","with open(json_file_path, 'r') as file:\n","    data = json.load(file)\n","\n","# Initialize empty lists for each column\n","tokens_list = []\n","aspects_list = []\n","bio_tags_list = []\n","token_length_list = []\n","\n","# Process each entry in the data\n","for entry in data:\n","    tokens = entry[\"token\"]\n","    aspects = entry.get(\"aspects\", [])\n","\n","    # Extract unique aspects as a list of terms\n","    unique_aspects = list(set(term for aspect in aspects for term in aspect.get(\"term\", [])))\n","\n","    # Initialize BIO tags list with 'O' (outside) for each token\n","    bio_tags = ['O'] * len(tokens)\n","\n","    # Process aspects and update BIO tags accordingly\n","    for aspect in aspects:\n","        term = aspect.get(\"term\", [])\n","        for i in range(len(tokens)):\n","            if tokens[i:i + len(term)] == term:\n","                if i > 0 and bio_tags[i - 1] == 'B':\n","                    bio_tags[i] = 'I'\n","                else:\n","                    bio_tags[i] = 'B'\n","                if len(term) > 1:\n","                    bio_tags[i + 1:i + len(term)] = ['I'] * (len(term) - 1)\n","\n","    # Append data to lists\n","    tokens_list.append(tokens)\n","    aspects_list.append(unique_aspects)  # Append unique aspects\n","    bio_tags_list.append(bio_tags)\n","    token_length_list.append([len(token) for token in tokens])\n","\n","# Create DataFrame\n","df_result = pd.DataFrame({\n","    'token': tokens_list,\n","    'aspect': aspects_list,\n","    'bioTag': bio_tags_list,\n","    'token_length': token_length_list\n","})\n","\n","# Display the DataFrame\n","print(df_result)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76hVB9IQfxJa","executionInfo":{"status":"ok","timestamp":1709455668209,"user_tz":-330,"elapsed":10,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"5fe79658-27ea-494b-b86d-85a852810181"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  token  \\\n","0       [But, the, staff, was, so, horrible, to, us, .]   \n","1     [To, be, completely, fair, ,, the, only, redee...   \n","2     [The, food, is, uniformly, exceptional, ,, wit...   \n","3     [Not, only, was, the, food, outstanding, ,, bu...   \n","4     [Our, agreed, favorite, is, the, orrechiete, w...   \n","...                                                 ...   \n","1975  [The, service, was, typical, short-order, ,, d...   \n","1976  [We, shared, a, bottle, of, sake, ,, an, order...   \n","1977  [I, ca, n't, believe, people, complain, about,...   \n","1978  [From, the, appetizers, we, ate, ,, the, dim, ...   \n","1979  [Each, table, has, a, pot, of, boiling, water,...   \n","\n","                                                 aspect  \\\n","0                                               [staff]   \n","1                                                [food]   \n","2                                 [kitchen, food, menu]   \n","3                                      [food, perks, ']   \n","4     [sausage, chicken, and, dish, meats, with, orr...   \n","...                                                 ...   \n","1975                                          [service]   \n","1976  [sake, of, edamames, sushi, bottle, sashimi, p...   \n","1977                                   [sticks, cheese]   \n","1978                [food, dim, foods, sum, appetizers]   \n","1979  [of, pot, glass, noodles, meats, vegetables, r...   \n","\n","                                                 bioTag  \\\n","0                           [O, O, B, O, O, O, O, O, O]   \n","1     [O, O, O, O, O, O, O, O, O, O, O, B, O, O, O, ...   \n","2     [O, B, O, O, O, O, O, O, O, O, B, O, O, O, O, ...   \n","3      [O, O, O, O, B, O, O, O, O, O, B, I, O, O, O, O]   \n","4     [O, O, O, O, O, B, I, I, I, I, O, O, O, B, O, ...   \n","...                                                 ...   \n","1975                        [O, B, O, O, O, O, O, O, O]   \n","1976  [O, O, O, B, I, I, O, O, O, O, B, O, O, O, O, ...   \n","1977                  [O, O, O, O, O, O, O, O, B, I, O]   \n","1978  [O, O, B, O, O, O, O, B, I, O, O, O, O, B, O, ...   \n","1979  [O, B, O, O, B, I, I, I, O, O, O, O, O, O, O, ...   \n","\n","                                           token_length  \n","0                           [3, 3, 5, 3, 2, 8, 2, 2, 1]  \n","1     [2, 2, 10, 4, 1, 3, 4, 9, 6, 3, 3, 4, 1, 5, 3,...  \n","2     [3, 4, 2, 9, 11, 1, 4, 1, 4, 7, 7, 5, 4, 7, 4,...  \n","3     [3, 4, 3, 3, 4, 11, 1, 3, 3, 6, 1, 5, 1, 4, 5, 1]  \n","4     [3, 6, 8, 2, 3, 10, 4, 7, 3, 7, 1, 7, 3, 7, 3,...  \n","...                                                 ...  \n","1975                       [3, 7, 3, 7, 11, 1, 6, 4, 1]  \n","1976  [2, 6, 1, 6, 2, 4, 1, 2, 5, 2, 8, 1, 3, 3, 3, ...  \n","1977                  [1, 2, 3, 7, 6, 8, 5, 2, 6, 6, 1]  \n","1978  [4, 3, 10, 2, 3, 1, 3, 3, 3, 3, 5, 7, 2, 5, 1,...  \n","1979  [4, 5, 3, 1, 3, 2, 7, 5, 6, 4, 3, 7, 1, 3, 3, ...  \n","\n","[1980 rows x 4 columns]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","\n","# Assuming your JSON file is named 'your_file.json'\n","json_file_path = '/content/drive/MyDrive/Common files/Common files/Dataset/Restaurants/train.json'\n","\n","# Read data from JSON file\n","with open(json_file_path, 'r') as file:\n","    data = json.load(file)\n","\n","# Initialize empty lists for each column\n","tokens_list = []\n","aspects_list = []\n","bio_tags_list = []\n","token_length_list = []\n","\n","# Process each entry in the data\n","for entry in data:\n","    tokens = entry[\"token\"]\n","    aspects = entry.get(\"aspects\", [])\n","\n","    # Extract unique aspects as a list of terms\n","    unique_aspects = list(set(term for aspect in aspects for term in aspect.get(\"term\", [])))\n","\n","    # Initialize BIO tags list with 'O' (outside) for each token\n","    bio_tags = ['O'] * len(tokens)\n","\n","    # Process aspects and update BIO tags accordingly\n","    for aspect in aspects:\n","        term = aspect.get(\"term\", [])\n","        for i in range(len(tokens)):\n","            if tokens[i:i + len(term)] == term:\n","                if i > 0 and bio_tags[i - 1] == 'B':\n","                    bio_tags[i] = 'I'\n","                else:\n","                    bio_tags[i] = 'B'\n","                if len(term) > 1:\n","                    bio_tags[i + 1:i + len(term)] = ['I'] * (len(term) - 1)\n","\n","    # Append data to lists\n","    tokens_list.append(tokens)\n","    aspects_list.append(unique_aspects)  # Append unique aspects\n","    bio_tags_list.append(bio_tags)\n","    token_length_list.append([len(token) for token in tokens])\n","\n","# Create DataFrame\n","df_result = pd.DataFrame({\n","    'token': tokens_list,\n","    'aspect': aspects_list,\n","    'bioTag': bio_tags_list,\n","    'token_length': token_length_list\n","})\n","\n","# Save DataFrame to CSV file\n","csv_output_path = 'output_file.csv'\n","df_result.to_csv(csv_output_path, index=False)\n","\n","# Display the DataFrame\n","print(df_result)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zygvyu4tiCg0","executionInfo":{"status":"ok","timestamp":1709456392363,"user_tz":-330,"elapsed":1216,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"61b44caa-a21e-4f57-9b61-1caefa938ab5"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  token  \\\n","0       [But, the, staff, was, so, horrible, to, us, .]   \n","1     [To, be, completely, fair, ,, the, only, redee...   \n","2     [The, food, is, uniformly, exceptional, ,, wit...   \n","3     [Not, only, was, the, food, outstanding, ,, bu...   \n","4     [Our, agreed, favorite, is, the, orrechiete, w...   \n","...                                                 ...   \n","1975  [The, service, was, typical, short-order, ,, d...   \n","1976  [We, shared, a, bottle, of, sake, ,, an, order...   \n","1977  [I, ca, n't, believe, people, complain, about,...   \n","1978  [From, the, appetizers, we, ate, ,, the, dim, ...   \n","1979  [Each, table, has, a, pot, of, boiling, water,...   \n","\n","                                                 aspect  \\\n","0                                               [staff]   \n","1                                                [food]   \n","2                                 [kitchen, food, menu]   \n","3                                      [food, perks, ']   \n","4     [sausage, chicken, and, dish, meats, with, orr...   \n","...                                                 ...   \n","1975                                          [service]   \n","1976  [sake, of, edamames, sushi, bottle, sashimi, p...   \n","1977                                   [sticks, cheese]   \n","1978                [food, dim, foods, sum, appetizers]   \n","1979  [of, pot, glass, noodles, meats, vegetables, r...   \n","\n","                                                 bioTag  \\\n","0                           [O, O, B, O, O, O, O, O, O]   \n","1     [O, O, O, O, O, O, O, O, O, O, O, B, O, O, O, ...   \n","2     [O, B, O, O, O, O, O, O, O, O, B, O, O, O, O, ...   \n","3      [O, O, O, O, B, O, O, O, O, O, B, I, O, O, O, O]   \n","4     [O, O, O, O, O, B, I, I, I, I, O, O, O, B, O, ...   \n","...                                                 ...   \n","1975                        [O, B, O, O, O, O, O, O, O]   \n","1976  [O, O, O, B, I, I, O, O, O, O, B, O, O, O, O, ...   \n","1977                  [O, O, O, O, O, O, O, O, B, I, O]   \n","1978  [O, O, B, O, O, O, O, B, I, O, O, O, O, B, O, ...   \n","1979  [O, B, O, O, B, I, I, I, O, O, O, O, O, O, O, ...   \n","\n","                                           token_length  \n","0                           [3, 3, 5, 3, 2, 8, 2, 2, 1]  \n","1     [2, 2, 10, 4, 1, 3, 4, 9, 6, 3, 3, 4, 1, 5, 3,...  \n","2     [3, 4, 2, 9, 11, 1, 4, 1, 4, 7, 7, 5, 4, 7, 4,...  \n","3     [3, 4, 3, 3, 4, 11, 1, 3, 3, 6, 1, 5, 1, 4, 5, 1]  \n","4     [3, 6, 8, 2, 3, 10, 4, 7, 3, 7, 1, 7, 3, 7, 3,...  \n","...                                                 ...  \n","1975                       [3, 7, 3, 7, 11, 1, 6, 4, 1]  \n","1976  [2, 6, 1, 6, 2, 4, 1, 2, 5, 2, 8, 1, 3, 3, 3, ...  \n","1977                  [1, 2, 3, 7, 6, 8, 5, 2, 6, 6, 1]  \n","1978  [4, 3, 10, 2, 3, 1, 3, 3, 3, 3, 5, 7, 2, 5, 1,...  \n","1979  [4, 5, 3, 1, 3, 2, 7, 5, 6, 4, 3, 7, 1, 3, 3, ...  \n","\n","[1980 rows x 4 columns]\n"]}]}]}