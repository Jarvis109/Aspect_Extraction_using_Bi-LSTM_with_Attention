{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOiOc9pvx0fmE80pKT887S9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7_SGMjVIDwz6","executionInfo":{"status":"ok","timestamp":1715236570330,"user_tz":-330,"elapsed":23824,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"ed10b11b-b715-47dc-e7d8-ca6e14b577c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","import json\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed, Dropout\n","from keras.preprocessing.text import Tokenizer\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","import gensim.downloader as api"],"metadata":{"id":"86DlMSuiERpY","executionInfo":{"status":"ok","timestamp":1715236588023,"user_tz":-330,"elapsed":8609,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAvQYIf1EUO4","executionInfo":{"status":"ok","timestamp":1715236635580,"user_tz":-330,"elapsed":1533,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"592b8f7b-b752-4267-c6b8-d2b5d0e8856f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["word_vectors = api.load('glove-wiki-gigaword-200')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXcZTOA1EUmr","executionInfo":{"status":"ok","timestamp":1715236794309,"user_tz":-330,"elapsed":158732,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"0049cbc6-022e-4d69-bf38-5174de055b66"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 252.1/252.1MB downloaded\n"]}]},{"cell_type":"code","source":["import nltk\n","import pandas as pd\n","import string\n","from nltk.corpus import stopwords\n","\n","def process_data(data):\n","    stop_words = set(stopwords.words('english'))\n","    punctuation = set(string.punctuation)\n","\n","    tokens_list = []\n","    aspects_list = []\n","    bio_tags_list = []\n","    token_length_list = []\n","    pos_tags_list = []\n","\n","    for entry in data:\n","        tokens = [token for token in entry[\"token\"] if token not in punctuation]\n","        aspects = entry.get(\"aspects\", [])\n","        pos_tags = nltk.pos_tag(tokens)\n","\n","        unique_aspects = []\n","        bio_tags = ['O'] * len(tokens)\n","\n","        for aspect in aspects:\n","            term = [char for char in aspect.get(\"term\", []) if char not in punctuation]\n","            unique_aspects.append(''.join(term))\n","\n","            for i in range(len(tokens)):\n","                if tokens[i:i + len(term)] == term:\n","                    if i > 0 and bio_tags[i - 1] == 'B':\n","                        bio_tags[i] = 'I'\n","                    else:\n","                        bio_tags[i] = 'B'\n","                    if len(term) > 1:\n","                        bio_tags[i + 1:i + len(term)] = ['I'] * (len(term) - 1)\n","\n","        filtered_tokens = tokens\n","        filtered_bio_tags = bio_tags\n","        filtered_pos_tags = [tag[1] for tag in pos_tags]\n","\n","        tokens_list.append(filtered_tokens)\n","        aspects_list.append(unique_aspects)\n","        bio_tags_list.append(filtered_bio_tags)\n","        token_length_list.append([len(token) for token in filtered_tokens])\n","        pos_tags_list.append(filtered_pos_tags)\n","\n","    df_result = pd.DataFrame({\n","        'token': tokens_list,\n","        'aspect': aspects_list,\n","        'bioTag': bio_tags_list,\n","        'pos': pos_tags_list,  # Add POS tags as a new column\n","    })\n","\n","    return df_result\n"],"metadata":{"id":"5vJBIXEYEg-M","executionInfo":{"status":"ok","timestamp":1715236798744,"user_tz":-330,"elapsed":3,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Load training data from JSON file\n","train_json_file_path = '/content/drive/MyDrive/Common files/Common files/Dataset/Laptops/train.json'\n","with open(train_json_file_path, 'r') as file:\n","    train_data = json.load(file)\n","test_json_file_path = '/content/drive/MyDrive/Common files/Common files/Dataset/Laptops/test.json'\n","with open(test_json_file_path, 'r') as file:\n","    test_data = json.load(file)\n","valid_json_file_path = '/content/drive/MyDrive/Common files/Common files/Dataset/Laptops/valid.json'\n","with open(valid_json_file_path, 'r') as file:\n","    valid_data = json.load(file)"],"metadata":{"id":"OXZIy-dJEjXN","executionInfo":{"status":"ok","timestamp":1715236805775,"user_tz":-330,"elapsed":2677,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["df_train = process_data(train_data)\n","df_test = process_data(test_data)\n","df_valid = process_data(valid_data)"],"metadata":{"id":"zYxQGgIXEkHt","executionInfo":{"status":"ok","timestamp":1715236865246,"user_tz":-330,"elapsed":1974,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import string\n","from nltk.corpus import stopwords\n","import nltk\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.models import Model\n","from keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed, Dropout, Input, Concatenate, Dot, Activation, multiply\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report\n","from gensim.models import KeyedVectors\n","\n","# Adjust tokenizer with a fixed maximum vocabulary size\n","MAX_VOCAB_SIZE = 5000\n","tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token='<OOV>')\n","tokenizer.fit_on_texts(df_train['token'])\n","tokenizer.fit_on_texts(df_train['pos'])\n","\n","# Set a fixed maximum sequence length\n","max_seq_length = 200\n","tag_to_index = {'O': 0, 'B': 1, 'I': 2,'PAD':3}\n","# Pad sequences with the fixed maximum sequence length\n","X_train = pad_sequences(tokenizer.texts_to_sequences(df_train['token']), maxlen=max_seq_length, padding='post', truncating='post')\n","X_test = pad_sequences(tokenizer.texts_to_sequences(df_test['token']), maxlen=max_seq_length, padding='post', truncating='post')\n","X_val = pad_sequences(tokenizer.texts_to_sequences(df_valid['token']), maxlen=max_seq_length, padding='post', truncating='post')\n","\n","# Pad POS sequences with the fixed maximum sequence length\n","pos_vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size for POS tags\n","X_train_pos = pad_sequences(tokenizer.texts_to_sequences(df_train['pos']), maxlen=max_seq_length, padding='post', truncating='post')\n","X_test_pos = pad_sequences(tokenizer.texts_to_sequences(df_test['pos']), maxlen=max_seq_length, padding='post', truncating='post')\n","X_val_pos = pad_sequences(tokenizer.texts_to_sequences(df_valid['pos']), maxlen=max_seq_length, padding='post', truncating='post')\n","\n","# Pad BIO tag sequences with the fixed maximum sequence length\n","y_train = pad_sequences([[tag_to_index[tag] for tag in seq] for seq in df_train['bioTag']], padding='post', value=3, maxlen=max_seq_length)\n","y_test = pad_sequences([[tag_to_index[tag] for tag in seq] for seq in df_test['bioTag']], padding='post', value=3, maxlen=max_seq_length)\n","y_val = pad_sequences([[tag_to_index[tag] for tag in seq] for seq in df_valid['bioTag']], padding='post', value=3, maxlen=max_seq_length)\n","\n","# Convert numerical representations to one-hot encoding\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","y_val = to_categorical(y_val)\n","\n","embedding_dim = 200  # Adjust based on the GloVe file you downloaded\n","embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n","for word, i in tokenizer.word_index.items():\n","    if word in word_vectors:\n","        embedding_matrix[i] = word_vectors[word]\n","\n","# Import necessary libraries\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.regularizers import l2\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","\n","# Compute class weights\n","# Compute class weights\n","# Compute class weights\n","# Calculate class weights manually\n","\n","\n","\n","\n","\n","# Define L2 regularization strength\n","l2_reg = 0.01\n","\n","# Update model architecture with regularization and class weights\n","def create_model_with_position_embeddings(embedding_matrix, max_seq_length, max_pos_length):\n","    # Input layers\n","    token_input_layer = Input(shape=(max_seq_length,))\n","    pos_input_layer = Input(shape=(max_seq_length,))\n","\n","    # Word embedding layer\n","    word_embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n","                                     output_dim=embedding_matrix.shape[1],\n","                                     input_length=max_seq_length,\n","                                     weights=[embedding_matrix],\n","                                     trainable=True, mask_zero=True)\n","    token_embedding = word_embedding_layer(token_input_layer)\n","\n","    # Positional embedding layer\n","    pos_embedding_layer = Embedding(input_dim=pos_vocab_size,\n","                                    output_dim=50,\n","                                    input_length=max_seq_length)\n","    pos_embedding = pos_embedding_layer(pos_input_layer)\n","\n","    # Concatenate token embeddings and positional embeddings\n","    combined_embedding = Concatenate(axis=-1)([token_embedding, pos_embedding])\n","\n","    # Dropout layer\n","    dropout_emb = Dropout(0.5)(combined_embedding)\n","\n","    # Regularization layer\n","    reg_emb = TimeDistributed(Dense(512, activation='relu', kernel_regularizer=l2(l2_reg)))(dropout_emb)\n","\n","    # Attention Mechanism\n","    attention = TimeDistributed(Dense(512, activation='relu'))(reg_emb)\n","    attention = TimeDistributed(Dense(1))(attention)\n","    attention = TimeDistributed(Dense(128, activation='relu'))(attention)\n","    attention = TimeDistributed(Dense(1))(attention)\n","    attention = Activation('softmax')(attention)\n","\n","    # Apply attention weights\n","    sent_representation = multiply([reg_emb, attention])\n","\n","    # Bidirectional LSTM layer\n","    lstm = Bidirectional(LSTM(units=100, return_sequences=True))(sent_representation)\n","\n","    # Self-Attention Mechanism\n","    self_attention = Dot(axes=[2, 2])([lstm, lstm])\n","    self_attention = Activation('softmax')(self_attention)\n","\n","    # Combine attention and self-attention\n","    combined_attention = Concatenate(axis=-1)([lstm, self_attention])\n","\n","    # Feedforward layers with regularization\n","    output = TimeDistributed(Dense(128, activation='tanh', kernel_regularizer=l2(l2_reg)))(combined_attention)\n","    output = Dropout(0.1)(output)\n","    output = TimeDistributed(Dense(4, activation='softmax'))(output)  # Assuming 3 classes: 'O', 'B', 'I'\n","\n","    # Create model\n","    model = Model(inputs=[token_input_layer, pos_input_layer], outputs=output)\n","\n","    return model\n"],"metadata":{"id":"yj9TosbAErcq","executionInfo":{"status":"ok","timestamp":1715238164138,"user_tz":-330,"elapsed":755,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Define static class weights\n","static_class_weights = {0: 1, 1: 3, 2: 3}  # Adjust weights based on the classification report\n","\n","# Create and compile the model with position embeddings\n","model_with_position_embeddings = create_model_with_position_embeddings(embedding_matrix, max_seq_length, len(tag_to_index))\n","model_with_position_embeddings.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","# Re-run the training process with the padded target labels and static class weights\n","model_with_position_embeddings.fit([X_train, X_train_pos], y_train, validation_data=([X_val, X_val_pos], y_val), epochs=50, batch_size=32,callbacks=[early_stopping])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tW29TVy0Et7P","executionInfo":{"status":"ok","timestamp":1715238225040,"user_tz":-330,"elapsed":55483,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"151b55d7-73a1-457c-f6b7-3595d8750919"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","46/46 [==============================] - 23s 231ms/step - loss: 3.5080 - accuracy: 0.8546 - val_loss: 1.7589 - val_accuracy: 0.8463\n","Epoch 2/50\n","46/46 [==============================] - 4s 78ms/step - loss: 1.0386 - accuracy: 0.8995 - val_loss: 0.6633 - val_accuracy: 0.8879\n","Epoch 3/50\n","46/46 [==============================] - 3s 62ms/step - loss: 0.4513 - accuracy: 0.9249 - val_loss: 0.3988 - val_accuracy: 0.9071\n","Epoch 4/50\n","46/46 [==============================] - 4s 82ms/step - loss: 0.3025 - accuracy: 0.9332 - val_loss: 0.3078 - val_accuracy: 0.9167\n","Epoch 5/50\n","46/46 [==============================] - 2s 40ms/step - loss: 0.2345 - accuracy: 0.9429 - val_loss: 0.2692 - val_accuracy: 0.9203\n","Epoch 6/50\n","46/46 [==============================] - 2s 39ms/step - loss: 0.2056 - accuracy: 0.9470 - val_loss: 0.2465 - val_accuracy: 0.9245\n","Epoch 7/50\n","46/46 [==============================] - 1s 32ms/step - loss: 0.1793 - accuracy: 0.9528 - val_loss: 0.2514 - val_accuracy: 0.9205\n","Epoch 8/50\n","46/46 [==============================] - 2s 39ms/step - loss: 0.1728 - accuracy: 0.9520 - val_loss: 0.2383 - val_accuracy: 0.9282\n","Epoch 9/50\n","46/46 [==============================] - 2s 34ms/step - loss: 0.1659 - accuracy: 0.9535 - val_loss: 0.2442 - val_accuracy: 0.9245\n","Epoch 10/50\n","46/46 [==============================] - 2s 35ms/step - loss: 0.1607 - accuracy: 0.9568 - val_loss: 0.2290 - val_accuracy: 0.9294\n","Epoch 11/50\n","46/46 [==============================] - 2s 50ms/step - loss: 0.1455 - accuracy: 0.9585 - val_loss: 0.2221 - val_accuracy: 0.9294\n","Epoch 12/50\n","46/46 [==============================] - 2s 46ms/step - loss: 0.1420 - accuracy: 0.9615 - val_loss: 0.2212 - val_accuracy: 0.9315\n","Epoch 13/50\n","46/46 [==============================] - 1s 26ms/step - loss: 0.1407 - accuracy: 0.9621 - val_loss: 0.2130 - val_accuracy: 0.9361\n","Epoch 14/50\n","46/46 [==============================] - 1s 33ms/step - loss: 0.1346 - accuracy: 0.9634 - val_loss: 0.2148 - val_accuracy: 0.9339\n","Epoch 15/50\n","46/46 [==============================] - 1s 29ms/step - loss: 0.1336 - accuracy: 0.9643 - val_loss: 0.2145 - val_accuracy: 0.9346\n","Epoch 16/50\n","46/46 [==============================] - 2s 35ms/step - loss: 0.1304 - accuracy: 0.9644 - val_loss: 0.2327 - val_accuracy: 0.9299\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7dc7f5145060>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score\n","\n","# Make predictions on the test set\n","y_pred = model_with_position_embeddings.predict([X_test, X_test_pos])\n","\n","# Convert predictions and true labels from one-hot encoding to labels\n","y_pred_labels = np.argmax(y_pred, axis=-1)\n","y_test_labels = np.argmax(y_test, axis=-1)\n","\n","# Flatten the predictions and true labels to prepare for classification_report\n","y_pred_labels_flat = y_pred_labels.flatten()\n","y_test_labels_flat = y_test_labels.flatten()\n","\n","# Generate classification report\n","class_names = ['O', 'B', 'I']\n","# Filter out 'PAD' tag from predictions and true labels\n","non_pad_indices = y_test_labels_flat != tag_to_index['PAD']\n","y_pred_labels_filtered = y_pred_labels_flat[non_pad_indices]\n","y_test_labels_filtered = y_test_labels_flat[non_pad_indices]\n","\n","# Generate classification report\n","report = classification_report(y_test_labels_filtered, y_pred_labels_filtered, target_names=class_names)\n","\n","\n","# Print classification report\n","print(\"Classification Report (excluding PAD tag):\")\n","print(report)\n","\n","# Calculate accuracy excluding 'PAD' tag\n","accuracy = accuracy_score(y_test_labels_filtered, y_pred_labels_filtered)\n","print(\"Accuracy (excluding PAD tag):\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_tESPrrQEyvP","executionInfo":{"status":"ok","timestamp":1715238261370,"user_tz":-330,"elapsed":1447,"user":{"displayName":"ANCHAL KUMAR CHAUDHARY CHAUDHARY","userId":"17164198114286982807"}},"outputId":"b624a9c0-5650-4586-abff-1b4544e36199"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["13/13 [==============================] - 0s 9ms/step\n","Classification Report (excluding PAD tag):\n","              precision    recall  f1-score   support\n","\n","           O       0.95      0.98      0.97      4776\n","           B       0.86      0.75      0.80       623\n","           I       0.80      0.70      0.75       425\n","\n","    accuracy                           0.94      5824\n","   macro avg       0.87      0.81      0.84      5824\n","weighted avg       0.93      0.94      0.93      5824\n","\n","Accuracy (excluding PAD tag): 0.9361263736263736\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QJVqWr4LEzBa"},"execution_count":null,"outputs":[]}]}